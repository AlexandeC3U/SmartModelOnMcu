{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c90976f",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "MNIST Optimization Lab (TensorFlow + TF-MOT + TFLite)\n",
    "====================================================\n",
    "\n",
    "\n",
    "A reproducible experimental harness to compare:\n",
    "- Baselines: ConvNet & Tiny DS-CNN\n",
    "- Pruning (magnitude, polynomial schedule)\n",
    "- Weight sharing (clustering)\n",
    "- Knowledge distillation (teacher: ConvNet, student: Tiny DS-CNN)\n",
    "- Quantization: PTQ (dynamic & full-int8) and QAT\n",
    "\n",
    "\n",
    "It logs accuracy, size, params, FLOPs, sparsity, and latency (TFLite) for each run.\n",
    "It also generates tables, plots, and a Markdown report.\n",
    "\n",
    "\n",
    "REQUIREMENTS\n",
    "------------\n",
    "- tensorflow >= 2.10\n",
    "- tensorflow-model-optimization >= 0.7\n",
    "- numpy, pandas, matplotlib, scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b66d288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import gc\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "import argparse\n",
    "import statistics as stats\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= '2.10', f\"TensorFlow >=2.10 required, found {tf.__version__}\"\n",
    "\n",
    "\n",
    "try:\n",
    "    import tensorflow_model_optimization as tfmot\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"tensorflow-model-optimization (tfmot) is required. pip install tensorflow-model-optimization\") from e\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee031d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Global config\n",
    "# ------------------------------------------------------------\n",
    "OUTDIR = Path(\"runs_mnist_opt\")\n",
    "(OUTDIR / \"models\").mkdir(parents=True, exist_ok=True)\n",
    "(OUTDIR / \"tflite\").mkdir(parents=True, exist_ok=True)\n",
    "(OUTDIR / \"figures\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "DEFAULT_EPOCHS = 6\n",
    "DEFAULT_BATCH = 128\n",
    "DEFAULT_SEEDS = 1\n",
    "WARMUP_RUNS = 5\n",
    "TIMED_RUNS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac012b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Helpers\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def set_global_seed(seed: int):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    try:\n",
    "        tf.config.experimental.enable_op_determinism()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def ensure_compiled(m):\n",
    "    if not getattr(m, \"_is_compiled\", False):\n",
    "        m.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return m\n",
    "\n",
    "def tflite_accuracy(tflite_bytes, x_test, y_test):\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_bytes)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "    correct = 0\n",
    "    total = x_test.shape[0]\n",
    "\n",
    "    for i in range(total):\n",
    "        sample = x_test[i:i+1]  # (1, 28, 28, 1)\n",
    "        # set input\n",
    "        idx = input_details['index']\n",
    "        if input_details['dtype'] == np.float32:\n",
    "            interpreter.set_tensor(idx, sample.astype(np.float32))\n",
    "        elif input_details['dtype'] == np.int8:\n",
    "            scale, zero_point = input_details['quantization']\n",
    "            q = (sample / scale + zero_point).astype(np.int8)\n",
    "            interpreter.set_tensor(idx, q)\n",
    "        elif input_details['dtype'] == np.uint8:\n",
    "            scale, zero_point = input_details['quantization']\n",
    "            q = (sample / scale + zero_point).astype(np.uint8)\n",
    "            interpreter.set_tensor(idx, q)\n",
    "        else:\n",
    "            raise RuntimeError(f\"Unsupported input dtype: {input_details['dtype']}\")\n",
    "\n",
    "        interpreter.invoke()\n",
    "        logits = interpreter.get_tensor(output_details['index'])\n",
    "        pred = int(np.argmax(logits, axis=1)[0])\n",
    "        correct += (pred == int(y_test[i]))\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aed530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Data: MNIST tf.data pipelines\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def load_mnist(batch_size=DEFAULT_BATCH):\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    x_train = x_train.astype(np.float32) / 255.0\n",
    "    x_test = x_test.astype(np.float32) / 255.0\n",
    "\n",
    "\n",
    "    # train/val split\n",
    "    val_count = 5000\n",
    "    x_val, y_val = x_train[-val_count:], y_train[-val_count:]\n",
    "    x_train, y_train = x_train[:-val_count], y_train[:-val_count]\n",
    "\n",
    "\n",
    "    def _prep(x, y):\n",
    "        x = np.expand_dims(x, -1) # (H,W,1)\n",
    "        return x, y.astype(np.int64)\n",
    "\n",
    "\n",
    "    x_train, y_train = _prep(x_train, y_train)\n",
    "    x_val, y_val = _prep(x_val, y_val)\n",
    "    x_test, y_test = _prep(x_test, y_test)\n",
    "\n",
    "\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    ds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "    return ds_train, ds_val, ds_test, (x_train, y_train, x_val, y_val, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ce9bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Model builders\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Convolutional model\n",
    "def build_conv_model(dropout=0.5):\n",
    "    m = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(28,28,1)),\n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2),\n",
    "        tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(10, activation='softmax'),\n",
    "    ], name='convnet')\n",
    "    return m\n",
    "\n",
    "\n",
    "# DSCNN model\n",
    "def build_tiny_dscnn():\n",
    "    inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "    x = tf.keras.layers.Conv2D(12, 3, strides=2, padding='same', use_bias=False)(inputs) # 14x14\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    # block 1\n",
    "    x = tf.keras.layers.DepthwiseConv2D(3, padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Conv2D(16, 1, padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    # block 2\n",
    "    x = tf.keras.layers.DepthwiseConv2D(3, strides=2, padding='same', use_bias=False)(x) # 7x7\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Conv2D(24, 1, padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "    return tf.keras.Model(inputs, outputs, name='tiny_dscnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba945dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Training, evaluation, and metrics\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_model(model, ds_train, ds_val, epochs=DEFAULT_EPOCHS, seed=0, outprefix=\"exp\"):\n",
    "    callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-5),\n",
    "    tf.keras.callbacks.CSVLogger(str(OUTDIR / f\"{outprefix}_history.csv\"), append=False),\n",
    "    ]\n",
    "    history = model.fit(ds_train, validation_data=ds_val, epochs=epochs, verbose=2, callbacks=callbacks)\n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, ds_test, x_test, y_test, prefix=\"exp\"):\n",
    "    test_loss, test_acc = model.evaluate(ds_test, verbose=0)\n",
    "    # Confusion matrix\n",
    "    y_prob = model.predict(ds_test, verbose=0)\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, digits=4)\n",
    "    np.save(OUTDIR / f\"{prefix}_cm.npy\", cm)\n",
    "    with open(OUTDIR / f\"{prefix}_cls_report.txt\", 'w') as f:\n",
    "        f.write(report)\n",
    "    return float(test_acc), cm, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a6c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# FLOPs, params, sparsity\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "def get_model_params(model):\n",
    "    return int(model.count_params())\n",
    "\n",
    "def get_model_flops(model):\n",
    "    try:\n",
    "        concrete = tf.function(model).get_concrete_function(tf.TensorSpec([1, 28, 28, 1], tf.float32))\n",
    "        frozen_func = tf.graph_util.convert_variables_to_constants_v2(concrete)\n",
    "        graph_def = frozen_func.graph.as_graph_def()\n",
    "        with tf.Graph().as_default() as graph:\n",
    "            tf.graph_util.import_graph_def(graph_def, name='')\n",
    "            run_meta = tf.compat.v1.RunMetadata()\n",
    "            opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "            flops = tf.compat.v1.profiler.profile(graph=graph, run_meta=run_meta, cmd='op', options=opts)\n",
    "            return int(flops.total_float_ops)\n",
    "    except Exception:\n",
    "        try:\n",
    "            from tensorflow.keras.utils import get_flops\n",
    "            return int(get_flops(model, batch_size=1))\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "def estimate_sparsity(model):\n",
    "    total = 0\n",
    "    zeros = 0\n",
    "    for w in model.get_weights():\n",
    "        total += w.size\n",
    "        zeros += np.count_nonzero(w == 0)\n",
    "    return zeros / total if total else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a9759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# TFLite conversion + latency benchmarking\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "def representative_data_gen(x_train, num_samples=100):\n",
    "    for i in range(min(num_samples, x_train.shape[0])):\n",
    "        yield [x_train[i:i+1].astype(np.float32)]\n",
    "\n",
    "\n",
    "def to_tflite(model, kind: str, x_train=None, int8_io=True):\n",
    "    if kind == 'float':\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        tflite = converter.convert()\n",
    "    elif kind == 'dynamic':\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        tflite = converter.convert()\n",
    "    elif kind == 'int8':\n",
    "        assert x_train is not None, \"x_train required for full-int8 PTQ\"\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.representative_dataset = lambda: representative_data_gen(x_train)\n",
    "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "        if int8_io:\n",
    "            converter.inference_input_type = tf.int8\n",
    "            converter.inference_output_type = tf.int8\n",
    "        tflite = converter.convert()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown tflite kind: {kind}\")\n",
    "    return tflite\n",
    "\n",
    "\n",
    "def _set_input(interpreter, sample):\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    tensor_index = input_details['index']\n",
    "    if input_details['dtype'] == np.float32:\n",
    "        interpreter.set_tensor(tensor_index, sample.astype(np.float32))\n",
    "    elif input_details['dtype'] == np.int8:\n",
    "        scale, zero_point = input_details['quantization']\n",
    "        quantized = (sample / scale + zero_point).astype(np.int8)\n",
    "        interpreter.set_tensor(tensor_index, quantized)\n",
    "    elif input_details['dtype'] == np.uint8:\n",
    "        scale, zero_point = input_details['quantization']\n",
    "        quantized = (sample / scale + zero_point).astype(np.uint8)\n",
    "        interpreter.set_tensor(tensor_index, quantized)\n",
    "    else:\n",
    "        raise RuntimeError(f\"Unsupported input dtype: {input_details['dtype']}\")\n",
    "    \n",
    "\n",
    "def tflite_latency(tflite_bytes, x_test, warmup=WARMUP_RUNS, runs=TIMED_RUNS):\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_bytes)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "\n",
    "    # prepare one sample repeatedly\n",
    "    sample = x_test[0:1]\n",
    "\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(warmup):\n",
    "        _set_input(interpreter, sample)\n",
    "    interpreter.invoke()\n",
    "\n",
    "\n",
    "    times = []\n",
    "    for _ in range(runs):\n",
    "        _set_input(interpreter, sample)\n",
    "    t0 = time.perf_counter_ns()\n",
    "    interpreter.invoke()\n",
    "    t1 = time.perf_counter_ns()\n",
    "    times.append((t1 - t0) / 1e6) # ms\n",
    "\n",
    "\n",
    "    return {\n",
    "    'mean_ms': float(np.mean(times)),\n",
    "    'median_ms': float(np.median(times)),\n",
    "    'p90_ms': float(np.percentile(times, 90)),\n",
    "    'p99_ms': float(np.percentile(times, 99)),\n",
    "    'min_ms': float(np.min(times)),\n",
    "    'max_ms': float(np.max(times)),\n",
    "    'runs': len(times),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "190a1697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Pruning (TF-MOT)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def apply_pruning(model, ds_train, epochs, target_sparsity=0.8):\n",
    "    \"\"\"Wrap model with pruning and fine-tune for 'epochs'.\"\"\"\n",
    "    steps_per_epoch = int(tf.data.experimental.cardinality(ds_train))\n",
    "    schedule = tfmot.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.0, final_sparsity=target_sparsity,\n",
    "        begin_step=0, end_step=epochs * steps_per_epoch)\n",
    "\n",
    "    pruned = tfmot.sparsity.keras.prune_low_magnitude(model, pruning_schedule=schedule)\n",
    "    pruned = compile_model(pruned)\n",
    "\n",
    "    callbacks = [\n",
    "        tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2, restore_best_weights=True),\n",
    "    ]\n",
    "    return pruned, callbacks\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42af23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Weight clustering\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "def apply_clustering(model, clusters=8):\n",
    "    try:\n",
    "        clustering = tfmot.clustering.keras\n",
    "        centroids_init = clustering.CentroidInitialization.LINEAR\n",
    "        clustered = clustering.cluster_weights(model, number_of_clusters=clusters, cluster_centroids_init=centroids_init)\n",
    "        clustered.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        return clustered\n",
    "    except Exception as e:\n",
    "        print(f\"Clustering unavailable or failed: {e}. Proceeding without clustering.\")\n",
    "        clone = tf.keras.models.clone_model(model)\n",
    "        clone.build((None, 28, 28, 1))\n",
    "        clone.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        return clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2550a35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Quantization-aware training (QAT)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "def apply_qat(model):\n",
    "    try:\n",
    "        quantize_model = tfmot.quantization.keras.quantize_model\n",
    "        # Ensure we pass a standard Keras model type\n",
    "        if not isinstance(model, (tf.keras.Sequential, tf.keras.Model)):\n",
    "            model = tf.keras.models.clone_model(model)\n",
    "        qat = quantize_model(model)\n",
    "        qat.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        return qat\n",
    "    except Exception as e:\n",
    "        print(f\"QAT unavailable or failed: {e}. Proceeding without QAT.\")\n",
    "        clone = tf.keras.models.clone_model(model)\n",
    "        clone.build((None, 28, 28, 1))\n",
    "        clone.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        return clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8693d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Knowledge Distillation (KD)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "class Distiller(tf.keras.Model):\n",
    "    def __init__(self, student, teacher, temperature=2.0, alpha=0.1):\n",
    "        super().__init__()\n",
    "        self.student = student\n",
    "        self.teacher = teacher\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.student_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        self.distill_loss_fn = tf.keras.losses.KLDivergence()\n",
    "        self.metrics_tracker = [tf.keras.metrics.SparseCategoricalAccuracy(name='acc')]\n",
    "\n",
    "\n",
    "    def compile(self, optimizer):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_tracker\n",
    "\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        teacher_probs = tf.nn.softmax(self.teacher(x, training=False) / self.temperature)\n",
    "        with tf.GradientTape() as tape:\n",
    "            student_logits = self.student(x, training=True)\n",
    "            student_loss = self.student_loss_fn(y, student_logits)\n",
    "            distill_loss = self.distill_loss_fn(teacher_probs, tf.nn.softmax(student_logits / self.temperature))\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distill_loss\n",
    "        grads = tape.gradient(loss, self.student.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.student.trainable_variables))\n",
    "        for m in self.metrics:\n",
    "            m.update_state(y, student_logits)\n",
    "        return {\"loss\": loss, **{m.name: m.result() for m in self.metrics}}\n",
    "\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        y_pred = self.student(x, training=False)\n",
    "        loss = self.student_loss_fn(y, y_pred)\n",
    "        for m in self.metrics:\n",
    "            m.update_state(y, y_pred)\n",
    "        return {\"loss\": loss, **{m.name: m.result() for m in self.metrics}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b785cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Orchestrator\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "def save_tflite(path, tflite_bytes):\n",
    "    Path(path).write_bytes(tflite_bytes)\n",
    "    return Path(path).stat().st_size\n",
    "\n",
    "def run_one_experiment(kind: str, base: str, seed: int, epochs: int, batch: int, ds_pack, arrays_pack):\n",
    "    ds_train, ds_val, ds_test = ds_pack\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = arrays_pack\n",
    "\n",
    "\n",
    "    set_global_seed(seed)\n",
    "    if base == 'conv':\n",
    "        base_model = build_conv_model()\n",
    "    elif base == 'dscnn':\n",
    "        base_model = build_tiny_dscnn()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown base model: {base}\")\n",
    "\n",
    "\n",
    "    exp_id = f\"{base}_{kind}_s{seed}\"\n",
    "    print(f\"\\n=== Running {exp_id} ===\")\n",
    "\n",
    "    # Build variant\n",
    "    if kind == 'baseline':\n",
    "        model = compile_model(base_model)\n",
    "        history = train_model(model, ds_train, ds_val, epochs=epochs, seed=seed, outprefix=exp_id)\n",
    "    elif kind.startswith('prune'):\n",
    "        target = float(kind.split('-')[1]) if '-' in kind else 0.8\n",
    "        pruned, callbacks = apply_pruning(base_model, ds_train, epochs, target_sparsity=target)\n",
    "        history = pruned.fit(ds_train, validation_data=ds_val, epochs=epochs, verbose=2, callbacks=callbacks)\n",
    "        model = tfmot.sparsity.keras.strip_pruning(pruned)\n",
    "        model.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    elif kind.startswith('cluster'):\n",
    "        clusters = int(kind.split('-')[1]) if '-' in kind else 8\n",
    "        clustered = apply_clustering(base_model, clusters=clusters)\n",
    "        history = clustered.fit(ds_train, validation_data=ds_val,\n",
    "                                epochs=max(2, epochs // 2), verbose=2)\n",
    "        model = tfmot.clustering.keras.strip_clustering(clustered)\n",
    "        model.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    elif kind == 'qat':\n",
    "        qat = apply_qat(base_model)\n",
    "        history = qat.fit(ds_train, validation_data=ds_val, epochs=epochs, verbose=2)\n",
    "        model = qat\n",
    "    elif kind == 'kd':\n",
    "        # teacher: trained ConvNet\n",
    "        teacher = build_conv_model()\n",
    "        teacher = compile_model(teacher)\n",
    "        teacher.fit(ds_train, validation_data=ds_val, epochs=epochs, verbose=0)\n",
    "\n",
    "        student = base_model\n",
    "        distiller = Distiller(student=student, teacher=teacher, temperature=2.0, alpha=0.2)\n",
    "        distiller.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "        history = distiller.fit(ds_train, validation_data=ds_val, epochs=epochs, verbose=2)\n",
    "        student.compile(optimizer='adam',\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "        model = student\n",
    "\n",
    "    # Evaluate FP32 Keras\n",
    "    model = ensure_compiled(model)\n",
    "    acc, cm, cls_rep = evaluate_model(model, ds_test, x_test, y_test, prefix=exp_id)\n",
    "\n",
    "    # FLOPs / params / sparsity\n",
    "    params = get_model_params(model)\n",
    "    flops = get_model_flops(model)\n",
    "    sparsity_est = estimate_sparsity(model)\n",
    "\n",
    "    # TFLite variants\n",
    "    sizes = {}\n",
    "    latencies = {}\n",
    "\n",
    "    # float32 tflite\n",
    "    tfl_float = to_tflite(model, kind='float')\n",
    "    sizes['tflite_float_bytes'] = save_tflite(OUTDIR / 'tflite' / f'{exp_id}_float.tflite', tfl_float)\n",
    "    latencies['tflite_float'] = tflite_latency(tfl_float, x_test)\n",
    "\n",
    "    # dynamic range PTQ\n",
    "    tfl_dyn = to_tflite(model, kind='dynamic')\n",
    "    sizes['tflite_dynamic_bytes'] = save_tflite(OUTDIR / 'tflite' / f'{exp_id}_dynamic.tflite', tfl_dyn)\n",
    "    latencies['tflite_dynamic'] = tflite_latency(tfl_dyn, x_test)\n",
    "\n",
    "    # full int8 PTQ\n",
    "    tfl_int8 = to_tflite(model, kind='int8', x_train=x_train)\n",
    "    sizes['tflite_int8_bytes'] = save_tflite(OUTDIR / 'tflite' / f'{exp_id}_int8.tflite', tfl_int8)\n",
    "    latencies['tflite_int8'] = tflite_latency(tfl_int8, x_test)\n",
    "\n",
    "    # TFLite accuracies\n",
    "    acc_float   = tflite_accuracy(tfl_float, x_test, y_test)\n",
    "    acc_dynamic = tflite_accuracy(tfl_dyn,   x_test, y_test)\n",
    "    acc_int8    = tflite_accuracy(tfl_int8,  x_test, y_test)\n",
    "\n",
    "    # Save Keras model\n",
    "    model_path = OUTDIR / 'models' / f'{exp_id}.keras'\n",
    "    model.save(model_path)\n",
    "    keras_bytes = sum(p.stat().st_size for p in model_path.rglob('*')) if model_path.is_dir() else model_path.stat().st_size\n",
    "\n",
    "    row = {\n",
    "        'exp_id': exp_id,\n",
    "        'base': base,\n",
    "        'kind': kind,\n",
    "        'seed': seed,\n",
    "        'epochs': epochs,\n",
    "        'batch': batch,\n",
    "        'test_acc': acc,                 \n",
    "        'params': params,\n",
    "        'flops': flops,\n",
    "        'sparsity_est': sparsity_est,\n",
    "        'keras_bytes': keras_bytes,\n",
    "\n",
    "        # TFLite sizes\n",
    "        'tflite_float_bytes':  sizes['tflite_float_bytes'],\n",
    "        'tflite_dynamic_bytes': sizes['tflite_dynamic_bytes'],\n",
    "        'tflite_int8_bytes':   sizes['tflite_int8_bytes'],\n",
    "\n",
    "        # TFLite latencies\n",
    "        'tflite_float_median_ms':   latencies['tflite_float']['median_ms'],\n",
    "        'tflite_dynamic_median_ms': latencies['tflite_dynamic']['median_ms'],\n",
    "        'tflite_int8_median_ms':    latencies['tflite_int8']['median_ms'],\n",
    "\n",
    "        # TFLite accuracies\n",
    "        'tflite_float_acc':   acc_float,\n",
    "        'tflite_dynamic_acc': acc_dynamic,\n",
    "        'tflite_int8_acc':    acc_int8,\n",
    "\n",
    "        # Comparison deltas/ratios\n",
    "        'acc_drop_int8':  acc - acc_int8,  # positive means int8 lost acc\n",
    "        'size_ratio_int8': keras_bytes / max(1, sizes['tflite_int8_bytes']),\n",
    "    }\n",
    "\n",
    "    row.update(sizes)\n",
    "    for k, v in latencies.items():\n",
    "        for mname, mval in v.items():\n",
    "            row[f'{k}_{mname}'] = mval\n",
    "\n",
    "\n",
    "    # Persist confusion matrix\n",
    "    return row\n",
    "\n",
    "\n",
    "def run_suite(which: str, seeds: int, epochs: int, batch: int):\n",
    "    ds_train, ds_val, ds_test, arrays = load_mnist(batch)\n",
    "\n",
    "\n",
    "    # Define experiment recipes\n",
    "    recipes = []\n",
    "    if which in ('baseline', 'all'):\n",
    "        recipes += [('baseline', 'conv'), ('baseline', 'dscnn')]\n",
    "    if which in ('prune', 'all'):\n",
    "        recipes += [(f'prune-0.8', 'conv'), (f'prune-0.8', 'dscnn')]\n",
    "    if which in ('cluster', 'all'):\n",
    "         recipes += [(f'cluster-8', 'conv'), (f'cluster-8', 'dscnn')]\n",
    "    if which in ('qat', 'all'):\n",
    "        recipes += [('qat', 'conv'), ('qat', 'dscnn')]\n",
    "    if which in ('kd', 'all'):\n",
    "        recipes += [('kd', 'dscnn')]\n",
    "\n",
    "    rows = []\n",
    "    for (kind, base) in recipes:\n",
    "        for s in range(seeds):\n",
    "            row = run_one_experiment(kind=kind, base=base, seed=s, epochs=epochs, batch=batch, ds_pack=(ds_train, ds_val, ds_test), arrays_pack=arrays)\n",
    "            rows.append(row)\n",
    "            df = pd.DataFrame(rows)\n",
    "            df.to_csv(OUTDIR / 'results.csv', index=False)\n",
    "            gc.collect()\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(OUTDIR / 'results.csv', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d02757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Reporting: figures + Markdown\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "def plot_scatter(df, x, y, label='exp_id', fname='scatter.png'):\n",
    "    plt.figure()\n",
    "    plt.scatter(df[x].values, df[y].values)\n",
    "    texts = []\n",
    "    if label:\n",
    "        for _, row in df.iterrows():\n",
    "            texts.append(\n",
    "                plt.text(row[x], row[y], str(row[label]), fontsize=8)\n",
    "            )\n",
    "        try:\n",
    "            adjust_text(texts, arrowprops=dict(arrowstyle=\"->\", color='gray', lw=0.5))\n",
    "        except Exception:\n",
    "            pass\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTDIR / 'figures' / fname, dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def pareto_front(df, x_col, y_col):\n",
    "    pts = df[[x_col, y_col, 'exp_id']].values\n",
    "    pts = sorted(pts, key=lambda r: (r[0], -r[1]))\n",
    "    front = []\n",
    "    best_y = -1\n",
    "    for x, y, name in pts:\n",
    "        if y > best_y:\n",
    "            front.append((x, y, name))\n",
    "            best_y = y\n",
    "    return front\n",
    "\n",
    "def build_report(csv_path=OUTDIR / 'results.csv'):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'tflite_int8_median_ms' in df.columns:\n",
    "        plot_scatter(df, 'tflite_int8_median_ms', 'test_acc', label='exp_id', fname='acc_vs_latency_int8.png')\n",
    "    plot_scatter(df, 'params', 'test_acc', label='exp_id', fname='acc_vs_params.png')\n",
    "    if 'tflite_int8_bytes' in df.columns:\n",
    "        plot_scatter(df, 'tflite_int8_bytes', 'test_acc', label='exp_id', fname='acc_vs_size_int8.png')\n",
    "\n",
    "\n",
    "    # Pareto summary (latency vs acc using int8 median)\n",
    "    pareto = []\n",
    "    if 'tflite_int8_median_ms' in df.columns:\n",
    "        pf = pareto_front(df, 'tflite_int8_median_ms', 'test_acc')\n",
    "        pareto = [{'exp_id': n, 'latency_ms': x, 'acc': y} for (x, y, n) in pf]\n",
    "\n",
    "\n",
    "    # Markdown\n",
    "    md = io.StringIO()\n",
    "    md.write(\"# MNIST Optimization Report\\n\\n\")\n",
    "    md.write(\"## Summary\\n\\n\")\n",
    "    md.write(f\"Experiments: {len(df)}\\n\\n\")\n",
    "    if pareto:\n",
    "        md.write(\"### Pareto Frontier (latency vs accuracy, int8)\\n\\n\")\n",
    "        for p in pareto:\n",
    "            md.write(f\"- {p['exp_id']}: {p['acc']:.4f} acc @ {p['latency_ms']:.3f} ms\\n\")\n",
    "        md.write(\"\\n\")\n",
    "\n",
    "\n",
    "    md.write(\"## Results Table (top 10 by accuracy)\\n\\n\")\n",
    "    top = df.sort_values('test_acc', ascending=False).head(10)\n",
    "    md.write(top.to_markdown(index=False))\n",
    "    md.write(\"\\n\\n## Figures\\n\\n\")\n",
    "    for fig in ['acc_vs_latency_int8.png', 'acc_vs_params.png', 'acc_vs_size_int8.png']:\n",
    "        fig_path = OUTDIR / 'figures' / fig\n",
    "        if fig_path.exists():\n",
    "            md.write(f\"![{fig}]({fig_path.as_posix()})\\n\\n\")\n",
    "\n",
    "\n",
    "    # --- TFLite vs Keras comparison table ---\n",
    "    cols = [\n",
    "        'exp_id','kind','test_acc',\n",
    "        'tflite_float_acc','tflite_dynamic_acc','tflite_int8_acc',\n",
    "        'acc_drop_int8',\n",
    "        'keras_bytes','tflite_float_bytes','tflite_int8_bytes',\n",
    "        'tflite_float_median_ms','tflite_int8_median_ms',\n",
    "        'size_ratio_int8'\n",
    "    ]\n",
    "    have = [c for c in cols if c in df.columns]\n",
    "    comp = df[have].sort_values('test_acc', ascending=False).head(12)\n",
    "\n",
    "    md.write(\"## Keras vs TFLite comparison\\n\\n\")\n",
    "    try:\n",
    "        md.write(comp.to_markdown(index=False))\n",
    "    except Exception:\n",
    "        md.write(comp.to_csv(index=False))\n",
    "    md.write(\"\\n\\n\")\n",
    "\n",
    "    # --- Figure: grouped latency bars (float vs int8) ---\n",
    "    try:\n",
    "        sub = df.sort_values('test_acc', ascending=False).head(12)\n",
    "        labels = sub['exp_id'].tolist()\n",
    "        x = np.arange(len(labels))\n",
    "        width = 0.35\n",
    "\n",
    "        plt.figure(figsize=(max(8, len(labels)*0.6), 4.5))\n",
    "        plt.bar(x - width/2, sub['tflite_float_median_ms'], width, label='TFLite float median ms')\n",
    "        plt.bar(x + width/2, sub['tflite_int8_median_ms'],  width, label='TFLite int8 median ms')\n",
    "        plt.xticks(x, labels, rotation=45, ha='right')\n",
    "        plt.ylabel('median latency (ms)')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUTDIR / 'figures' / 'tflite_latency_bar.png', dpi=180)\n",
    "        plt.close()\n",
    "\n",
    "        md.write(\"### Latency: float vs int8 (median)\\n\\n\")\n",
    "        md.write(\"![tflite_latency_bar](figures/tflite_latency_bar.png)\\n\\n\")\n",
    "    except Exception as e:\n",
    "        md.write(f\"Latency bar plot skipped: {e}\\n\\n\")\n",
    "\n",
    "    # --- Figure: accuracy drop vs size ratio (int8) ---\n",
    "    if set(['acc_drop_int8','size_ratio_int8']).issubset(df.columns):\n",
    "        try:\n",
    "            plt.figure(figsize=(6.5, 4.5))\n",
    "            plt.scatter(df['size_ratio_int8'], df['acc_drop_int8'])\n",
    "            texts = []\n",
    "            for _, r in df.iterrows():\n",
    "                texts.append(plt.text(r['size_ratio_int8'], r['acc_drop_int8'], r['exp_id'], fontsize=8))\n",
    "            try:\n",
    "                adjust_text(texts, arrowprops=dict(arrowstyle=\"->\", color='gray', lw=0.5))\n",
    "            except Exception:\n",
    "                pass\n",
    "            plt.xlabel('size ratio (keras_bytes / tflite_int8_bytes)')\n",
    "            plt.ylabel('accuracy drop (Keras acc - TFLite int8 acc)')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(OUTDIR / 'figures' / 'tflite_accdrop_vs_sizeratio.png', dpi=180)\n",
    "            plt.close()\n",
    "\n",
    "            md.write(\"### Accuracy drop vs size ratio (int8)\\n\\n\")\n",
    "            md.write(\"![tflite_accdrop_vs_sizeratio](figures/tflite_accdrop_vs_sizeratio.png)\\n\\n\")\n",
    "        except Exception as e:\n",
    "            md.write(f\"Acc vs size plot skipped: {e}\\n\\n\")\n",
    "\n",
    "    \n",
    "    md.write(\"## Training accuracy curves\\n\\n\")\n",
    "    for _, r in df.sort_values('test_acc', ascending=False).iterrows():\n",
    "        figp = OUTDIR / 'figures' / f\"{r['exp_id']}_acc.png\"\n",
    "        if figp.exists():\n",
    "            md.write(f\"**{r['exp_id']}**\\n\\n\")\n",
    "            md.write(f\"![{r['exp_id']} accuracy](figures/{figp.name})\\n\\n\")\n",
    "\n",
    "\n",
    "    report_path = OUTDIR / 'MNIST_Optimization_Report.md'\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(md.getvalue())\n",
    "    print(f\"Report written to {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91d1b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\backend.py:1400: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "\n",
      "=== Running conv_baseline_s0 ===\n",
      "WARNING:tensorflow:From c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\optimizers\\__init__.py:317: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "430/430 - 4s - loss: 0.3643 - accuracy: 0.8902 - val_loss: 0.0798 - val_accuracy: 0.9776 - lr: 0.0010 - 4s/epoch - 8ms/step\n",
      "Epoch 2/10\n",
      "430/430 - 3s - loss: 0.1081 - accuracy: 0.9666 - val_loss: 0.0525 - val_accuracy: 0.9850 - lr: 0.0010 - 3s/epoch - 6ms/step\n",
      "Epoch 3/10\n",
      "430/430 - 3s - loss: 0.0833 - accuracy: 0.9742 - val_loss: 0.0471 - val_accuracy: 0.9872 - lr: 0.0010 - 3s/epoch - 6ms/step\n",
      "Epoch 4/10\n",
      "430/430 - 3s - loss: 0.0700 - accuracy: 0.9786 - val_loss: 0.0407 - val_accuracy: 0.9884 - lr: 0.0010 - 3s/epoch - 6ms/step\n",
      "Epoch 5/10\n",
      "430/430 - 3s - loss: 0.0604 - accuracy: 0.9815 - val_loss: 0.0377 - val_accuracy: 0.9892 - lr: 0.0010 - 3s/epoch - 6ms/step\n",
      "Epoch 6/10\n",
      "430/430 - 3s - loss: 0.0536 - accuracy: 0.9830 - val_loss: 0.0326 - val_accuracy: 0.9908 - lr: 0.0010 - 3s/epoch - 6ms/step\n",
      "Epoch 7/10\n",
      "430/430 - 3s - loss: 0.0517 - accuracy: 0.9835 - val_loss: 0.0361 - val_accuracy: 0.9900 - lr: 0.0010 - 3s/epoch - 6ms/step\n",
      "Epoch 8/10\n",
      "430/430 - 3s - loss: 0.0493 - accuracy: 0.9844 - val_loss: 0.0336 - val_accuracy: 0.9916 - lr: 0.0010 - 3s/epoch - 6ms/step\n",
      "Epoch 9/10\n",
      "430/430 - 3s - loss: 0.0407 - accuracy: 0.9867 - val_loss: 0.0306 - val_accuracy: 0.9924 - lr: 5.0000e-04 - 3s/epoch - 6ms/step\n",
      "Epoch 10/10\n",
      "430/430 - 3s - loss: 0.0381 - accuracy: 0.9880 - val_loss: 0.0311 - val_accuracy: 0.9920 - lr: 5.0000e-04 - 3s/epoch - 6ms/step\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmp547wcie3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmp547wcie3\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpxo7dbebo\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpxo7dbebo\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpq8sw_hji\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpq8sw_hji\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running dscnn_baseline_s0 ===\n",
      "Epoch 1/10\n",
      "430/430 - 3s - loss: 1.8223 - accuracy: 0.4022 - val_loss: 2.3739 - val_accuracy: 0.1140 - lr: 0.0010 - 3s/epoch - 8ms/step\n",
      "Epoch 2/10\n",
      "430/430 - 2s - loss: 1.0152 - accuracy: 0.7338 - val_loss: 0.9305 - val_accuracy: 0.6786 - lr: 0.0010 - 2s/epoch - 5ms/step\n",
      "Epoch 3/10\n",
      "430/430 - 2s - loss: 0.5757 - accuracy: 0.8711 - val_loss: 0.4988 - val_accuracy: 0.8682 - lr: 0.0010 - 2s/epoch - 5ms/step\n",
      "Epoch 4/10\n",
      "430/430 - 2s - loss: 0.3890 - accuracy: 0.9084 - val_loss: 0.3920 - val_accuracy: 0.8904 - lr: 0.0010 - 2s/epoch - 5ms/step\n",
      "Epoch 5/10\n",
      "430/430 - 2s - loss: 0.3094 - accuracy: 0.9224 - val_loss: 0.3673 - val_accuracy: 0.8834 - lr: 0.0010 - 2s/epoch - 5ms/step\n",
      "Epoch 6/10\n",
      "430/430 - 2s - loss: 0.2665 - accuracy: 0.9291 - val_loss: 0.2177 - val_accuracy: 0.9464 - lr: 0.0010 - 2s/epoch - 5ms/step\n",
      "Epoch 7/10\n",
      "430/430 - 2s - loss: 0.2400 - accuracy: 0.9352 - val_loss: 0.2167 - val_accuracy: 0.9418 - lr: 0.0010 - 2s/epoch - 5ms/step\n",
      "Epoch 8/10\n",
      "430/430 - 2s - loss: 0.2206 - accuracy: 0.9390 - val_loss: 0.1819 - val_accuracy: 0.9510 - lr: 0.0010 - 2s/epoch - 5ms/step\n",
      "Epoch 9/10\n",
      "430/430 - 2s - loss: 0.2067 - accuracy: 0.9421 - val_loss: 0.1755 - val_accuracy: 0.9524 - lr: 0.0010 - 2s/epoch - 5ms/step\n",
      "Epoch 10/10\n",
      "430/430 - 2s - loss: 0.1939 - accuracy: 0.9456 - val_loss: 0.1978 - val_accuracy: 0.9432 - lr: 0.0010 - 2s/epoch - 5ms/step\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmp0atxwdnn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmp0atxwdnn\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpyinex82j\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpyinex82j\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpfkhrrg2t\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpfkhrrg2t\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running conv_prune-0.8_s0 ===\n",
      "Epoch 1/10\n",
      "430/430 - 4s - loss: 0.3674 - accuracy: 0.8897 - val_loss: 0.0815 - val_accuracy: 0.9768 - 4s/epoch - 10ms/step\n",
      "Epoch 2/10\n",
      "430/430 - 3s - loss: 0.1171 - accuracy: 0.9643 - val_loss: 0.0590 - val_accuracy: 0.9826 - 3s/epoch - 7ms/step\n",
      "Epoch 3/10\n",
      "430/430 - 3s - loss: 0.0944 - accuracy: 0.9715 - val_loss: 0.0531 - val_accuracy: 0.9856 - 3s/epoch - 6ms/step\n",
      "Epoch 4/10\n",
      "430/430 - 3s - loss: 0.0821 - accuracy: 0.9753 - val_loss: 0.0489 - val_accuracy: 0.9880 - 3s/epoch - 7ms/step\n",
      "Epoch 5/10\n",
      "430/430 - 3s - loss: 0.0769 - accuracy: 0.9767 - val_loss: 0.0453 - val_accuracy: 0.9888 - 3s/epoch - 6ms/step\n",
      "Epoch 6/10\n",
      "430/430 - 3s - loss: 0.0751 - accuracy: 0.9770 - val_loss: 0.0438 - val_accuracy: 0.9894 - 3s/epoch - 6ms/step\n",
      "Epoch 7/10\n",
      "430/430 - 3s - loss: 0.0733 - accuracy: 0.9786 - val_loss: 0.0455 - val_accuracy: 0.9892 - 3s/epoch - 6ms/step\n",
      "Epoch 8/10\n",
      "430/430 - 3s - loss: 0.0702 - accuracy: 0.9786 - val_loss: 0.0410 - val_accuracy: 0.9900 - 3s/epoch - 7ms/step\n",
      "Epoch 9/10\n",
      "430/430 - 3s - loss: 0.0673 - accuracy: 0.9798 - val_loss: 0.0409 - val_accuracy: 0.9888 - 3s/epoch - 8ms/step\n",
      "Epoch 10/10\n",
      "430/430 - 3s - loss: 0.0643 - accuracy: 0.9801 - val_loss: 0.0401 - val_accuracy: 0.9904 - 3s/epoch - 7ms/step\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmp1qhtwj9w\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmp1qhtwj9w\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmp__j3vzhf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmp__j3vzhf\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpgff5ww7x\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpgff5ww7x\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running dscnn_prune-0.8_s0 ===\n",
      "Epoch 1/10\n",
      "430/430 - 4s - loss: 1.8512 - accuracy: 0.3751 - val_loss: 2.1970 - val_accuracy: 0.1148 - 4s/epoch - 10ms/step\n",
      "Epoch 2/10\n",
      "430/430 - 2s - loss: 1.1678 - accuracy: 0.6534 - val_loss: 1.1423 - val_accuracy: 0.6308 - 2s/epoch - 5ms/step\n",
      "Epoch 3/10\n",
      "430/430 - 2s - loss: 0.7757 - accuracy: 0.8021 - val_loss: 0.8077 - val_accuracy: 0.7378 - 2s/epoch - 5ms/step\n",
      "Epoch 4/10\n",
      "430/430 - 2s - loss: 0.6257 - accuracy: 0.8325 - val_loss: 1.0352 - val_accuracy: 0.6308 - 2s/epoch - 5ms/step\n",
      "Epoch 5/10\n",
      "430/430 - 2s - loss: 0.5871 - accuracy: 0.8414 - val_loss: 0.8202 - val_accuracy: 0.7052 - 2s/epoch - 5ms/step\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmp6ky_dbc5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmp6ky_dbc5\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpj77_18g4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpj77_18g4\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpwdkas6u9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpwdkas6u9\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running conv_cluster-8_s0 ===\n",
      "Epoch 1/5\n",
      "430/430 - 3s - loss: 0.3062 - accuracy: 0.9145 - val_loss: 0.0917 - val_accuracy: 0.9750 - 3s/epoch - 7ms/step\n",
      "Epoch 2/5\n",
      "430/430 - 3s - loss: 0.0866 - accuracy: 0.9735 - val_loss: 0.0647 - val_accuracy: 0.9820 - 3s/epoch - 6ms/step\n",
      "Epoch 3/5\n",
      "430/430 - 3s - loss: 0.0666 - accuracy: 0.9794 - val_loss: 0.0559 - val_accuracy: 0.9858 - 3s/epoch - 7ms/step\n",
      "Epoch 4/5\n",
      "430/430 - 3s - loss: 0.0560 - accuracy: 0.9825 - val_loss: 0.0551 - val_accuracy: 0.9858 - 3s/epoch - 7ms/step\n",
      "Epoch 5/5\n",
      "430/430 - 3s - loss: 0.0498 - accuracy: 0.9845 - val_loss: 0.0480 - val_accuracy: 0.9864 - 3s/epoch - 7ms/step\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmp6k47ytiy\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmp6k47ytiy\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmppteakjh1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmppteakjh1\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpek6yd40z\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpek6yd40z\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running dscnn_cluster-8_s0 ===\n",
      "Epoch 1/5\n",
      "430/430 - 3s - loss: 2.0778 - accuracy: 0.2245 - val_loss: 1.6313 - val_accuracy: 0.3520 - 3s/epoch - 6ms/step\n",
      "Epoch 2/5\n",
      "430/430 - 2s - loss: 1.4077 - accuracy: 0.4960 - val_loss: 1.1571 - val_accuracy: 0.5216 - 2s/epoch - 4ms/step\n",
      "Epoch 3/5\n",
      "430/430 - 2s - loss: 1.1112 - accuracy: 0.6145 - val_loss: 1.0240 - val_accuracy: 0.6634 - 2s/epoch - 4ms/step\n",
      "Epoch 4/5\n",
      "430/430 - 2s - loss: 0.8855 - accuracy: 0.7104 - val_loss: 0.8823 - val_accuracy: 0.6886 - 2s/epoch - 4ms/step\n",
      "Epoch 5/5\n",
      "430/430 - 2s - loss: 0.8192 - accuracy: 0.7306 - val_loss: 0.6273 - val_accuracy: 0.8148 - 2s/epoch - 4ms/step\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmplr940wfq\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmplr940wfq\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmp7qeh48jn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmp7qeh48jn\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpnf43gho8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpnf43gho8\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running conv_qat_s0 ===\n",
      "Epoch 1/10\n",
      "430/430 - 4s - loss: 0.3746 - accuracy: 0.8857 - val_loss: 0.0799 - val_accuracy: 0.9780 - 4s/epoch - 10ms/step\n",
      "Epoch 2/10\n",
      "430/430 - 4s - loss: 0.1138 - accuracy: 0.9658 - val_loss: 0.0600 - val_accuracy: 0.9844 - 4s/epoch - 9ms/step\n",
      "Epoch 3/10\n",
      "430/430 - 4s - loss: 0.0864 - accuracy: 0.9741 - val_loss: 0.0464 - val_accuracy: 0.9882 - 4s/epoch - 10ms/step\n",
      "Epoch 4/10\n",
      "430/430 - 4s - loss: 0.0723 - accuracy: 0.9781 - val_loss: 0.0437 - val_accuracy: 0.9880 - 4s/epoch - 10ms/step\n",
      "Epoch 5/10\n",
      "430/430 - 4s - loss: 0.0636 - accuracy: 0.9800 - val_loss: 0.0378 - val_accuracy: 0.9884 - 4s/epoch - 10ms/step\n",
      "Epoch 6/10\n",
      "430/430 - 4s - loss: 0.0565 - accuracy: 0.9825 - val_loss: 0.0340 - val_accuracy: 0.9898 - 4s/epoch - 9ms/step\n",
      "Epoch 7/10\n",
      "430/430 - 4s - loss: 0.0521 - accuracy: 0.9839 - val_loss: 0.0362 - val_accuracy: 0.9902 - 4s/epoch - 10ms/step\n",
      "Epoch 8/10\n",
      "430/430 - 4s - loss: 0.0478 - accuracy: 0.9854 - val_loss: 0.0318 - val_accuracy: 0.9912 - 4s/epoch - 10ms/step\n",
      "Epoch 9/10\n",
      "430/430 - 4s - loss: 0.0474 - accuracy: 0.9854 - val_loss: 0.0306 - val_accuracy: 0.9910 - 4s/epoch - 10ms/step\n",
      "Epoch 10/10\n",
      "430/430 - 4s - loss: 0.0418 - accuracy: 0.9871 - val_loss: 0.0306 - val_accuracy: 0.9912 - 4s/epoch - 9ms/step\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpgoue8w94\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpgoue8w94\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpntltd6ep\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpntltd6ep\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmp7aqx3se7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmp7aqx3se7\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running dscnn_qat_s0 ===\n",
      "Epoch 1/10\n",
      "430/430 - 4s - loss: 1.8155 - accuracy: 0.3985 - val_loss: 1.6702 - val_accuracy: 0.4696 - 4s/epoch - 9ms/step\n",
      "Epoch 2/10\n",
      "430/430 - 3s - loss: 1.0596 - accuracy: 0.7185 - val_loss: 1.5637 - val_accuracy: 0.3660 - 3s/epoch - 7ms/step\n",
      "Epoch 3/10\n",
      "430/430 - 3s - loss: 0.6326 - accuracy: 0.8588 - val_loss: 0.5269 - val_accuracy: 0.8610 - 3s/epoch - 7ms/step\n",
      "Epoch 4/10\n",
      "430/430 - 3s - loss: 0.4411 - accuracy: 0.8951 - val_loss: 0.3837 - val_accuracy: 0.9124 - 3s/epoch - 7ms/step\n",
      "Epoch 5/10\n",
      "430/430 - 3s - loss: 0.3481 - accuracy: 0.9131 - val_loss: 0.3732 - val_accuracy: 0.9030 - 3s/epoch - 7ms/step\n",
      "Epoch 6/10\n",
      "430/430 - 3s - loss: 0.2976 - accuracy: 0.9210 - val_loss: 0.2893 - val_accuracy: 0.9236 - 3s/epoch - 7ms/step\n",
      "Epoch 7/10\n",
      "430/430 - 3s - loss: 0.2625 - accuracy: 0.9287 - val_loss: 0.3073 - val_accuracy: 0.9122 - 3s/epoch - 7ms/step\n",
      "Epoch 8/10\n",
      "430/430 - 3s - loss: 0.2397 - accuracy: 0.9348 - val_loss: 0.2110 - val_accuracy: 0.9422 - 3s/epoch - 7ms/step\n",
      "Epoch 9/10\n",
      "430/430 - 3s - loss: 0.2239 - accuracy: 0.9377 - val_loss: 0.2523 - val_accuracy: 0.9240 - 3s/epoch - 7ms/step\n",
      "Epoch 10/10\n",
      "430/430 - 3s - loss: 0.2123 - accuracy: 0.9393 - val_loss: 0.3107 - val_accuracy: 0.8988 - 3s/epoch - 7ms/step\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpj3h_zqyq\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpj3h_zqyq\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmppw1k5qb1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmppw1k5qb1\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpqv5gjtg7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpqv5gjtg7\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running dscnn_kd_s0 ===\n",
      "Epoch 1/10\n",
      "430/430 - 4s - loss: 0.2811 - acc: 0.4032 - val_loss: 2.5530 - val_acc: 0.1300 - 4s/epoch - 9ms/step\n",
      "Epoch 2/10\n",
      "430/430 - 3s - loss: 0.1723 - acc: 0.7232 - val_loss: 0.9087 - val_acc: 0.5826 - 3s/epoch - 6ms/step\n",
      "Epoch 3/10\n",
      "430/430 - 3s - loss: 0.1299 - acc: 0.8537 - val_loss: 0.4626 - val_acc: 0.8364 - 3s/epoch - 6ms/step\n",
      "Epoch 4/10\n",
      "430/430 - 3s - loss: 0.0739 - acc: 0.8924 - val_loss: 0.3191 - val_acc: 0.9088 - 3s/epoch - 6ms/step\n",
      "Epoch 5/10\n",
      "430/430 - 3s - loss: 0.0619 - acc: 0.9190 - val_loss: 0.1898 - val_acc: 0.8950 - 3s/epoch - 7ms/step\n",
      "Epoch 6/10\n",
      "430/430 - 3s - loss: 0.0814 - acc: 0.9295 - val_loss: 0.2084 - val_acc: 0.8736 - 3s/epoch - 7ms/step\n",
      "Epoch 7/10\n",
      "430/430 - 3s - loss: 0.0438 - acc: 0.9362 - val_loss: 0.0641 - val_acc: 0.9532 - 3s/epoch - 7ms/step\n",
      "Epoch 8/10\n",
      "430/430 - 3s - loss: 0.0332 - acc: 0.9407 - val_loss: 0.0667 - val_acc: 0.9360 - 3s/epoch - 7ms/step\n",
      "Epoch 9/10\n",
      "430/430 - 3s - loss: 0.0467 - acc: 0.9440 - val_loss: 0.0578 - val_acc: 0.9480 - 3s/epoch - 7ms/step\n",
      "Epoch 10/10\n",
      "430/430 - 3s - loss: 0.0270 - acc: 0.9473 - val_loss: 0.0841 - val_acc: 0.9626 - 3s/epoch - 7ms/step\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpyyo1nfp5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpyyo1nfp5\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmptwdrfnby\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmptwdrfnby\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpg12yijdw\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ceulea\\AppData\\Local\\Temp\\tmpg12yijdw\\assets\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:863: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ceulea\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: runs_mnist_opt\\results.csv\n",
      "Report written to runs_mnist_opt\\MNIST_Optimization_Report.md\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# CLI\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def list_recipes():\n",
    "    print(\"Available experiment groups (use with --run):\")\n",
    "    print(\" baseline : ConvNet + Tiny DS-CNN\")\n",
    "    print(\" prune : Magnitude pruning to 80% sparsity\")\n",
    "    print(\" cluster : Weight clustering to 8 centroids\")\n",
    "    print(\" qat : Quantization-aware training\")\n",
    "    print(\" kd : Distill ConvNet -> Tiny DS-CNN\")\n",
    "    print(\" all : Everything above\")\n",
    "\n",
    "def main():\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument('--list', action='store_true', help='List available experiment groups and exit')\n",
    "    p.add_argument('--run', type=str, default='baseline', help='Which group to run: baseline|prune|cluster|qat|kd|all (comma-separated allowed)')\n",
    "    p.add_argument('--epochs', type=int, default=DEFAULT_EPOCHS)\n",
    "    p.add_argument('--batch', type=int, default=DEFAULT_BATCH)\n",
    "    p.add_argument('--seeds', type=int, default=DEFAULT_SEEDS)\n",
    "    p.add_argument('--report', action='store_true', help='Build figures + Markdown from existing CSV')\n",
    "    args = p.parse_args(args=[])\n",
    "\n",
    "    if args.list:\n",
    "        list_recipes()\n",
    "        return\n",
    "\n",
    "    if args.report:\n",
    "        build_report()\n",
    "        return\n",
    "\n",
    "    which_list = [w.strip() for w in args.run.split(',') if w.strip()]\n",
    "    all_rows = []\n",
    "    for which in which_list:\n",
    "        # df = run_suite(which=which, seeds=args.seeds, epochs=args.epochs, batch=args.batch)\n",
    "        df = run_suite(which='all', seeds=1, epochs=10, batch=128)\n",
    "        all_rows.append(df)\n",
    "    if all_rows:\n",
    "        df_all = pd.concat(all_rows).drop_duplicates(subset=['exp_id'])\n",
    "        df_all.to_csv(OUTDIR / 'results.csv', index=False)\n",
    "        print(\"Saved:\", OUTDIR / 'results.csv')\n",
    "        build_report()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
